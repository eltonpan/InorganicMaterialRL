{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/synthesisproject/anaconda3/envs/syn_gen_release/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/synthesisproject/anaconda3/envs/syn_gen_release/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/synthesisproject/anaconda3/envs/syn_gen_release/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/synthesisproject/anaconda3/envs/syn_gen_release/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/synthesisproject/anaconda3/envs/syn_gen_release/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/synthesisproject/anaconda3/envs/syn_gen_release/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0., 1., 0., 0., 0.])]\n",
      "[5, 2]\n",
      "torch.Size([1, 40, 115])\n",
      "torch.Size([1, 5])\n",
      "torch.Size([1, 80])\n",
      "torch.Size([1, 10])\n",
      "tensor([[-0.1549]], grad_fn=<AddmmBackward>)\n",
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from torch import nn\n",
    "import collections\n",
    "from model import DQN_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "# Load Q_data_random\n",
    "with open('./data/Q_data_random.pkl', 'rb') as f:\n",
    "    Q_data_random = pickle.load(f)\n",
    "\n",
    "print(len(Q_data_random))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s_material_inputs: torch.Size([5000, 40, 115])\n",
      "s_step_inputs: torch.Size([5000, 5])\n",
      "a_elem_inputs: torch.Size([5000, 80])\n",
      "a_comp_inputs: torch.Size([5000, 10])\n",
      "Q_targets: torch.Size([5000, 1])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dqn = DQN_pytorch()\n",
    "\n",
    "s_material_inputs = []\n",
    "s_step_inputs     = []\n",
    "a_elem_inputs     = []\n",
    "a_comp_inputs     = []\n",
    "Q_targets         = []\n",
    "\n",
    "for episode in Q_data_random:\n",
    "    for step in episode:\n",
    "        # state, action, reward = step\n",
    "        [s_material, s_step], [a_elem, a_comp], Q_target = step\n",
    "\n",
    "        s_material = torch.tensor(s_material)\n",
    "        s_step = torch.tensor(s_step)\n",
    "        a_elem = torch.tensor(a_elem)\n",
    "        a_comp = torch.tensor(a_comp)\n",
    "        Q_target = torch.tensor([Q_target])\n",
    "\n",
    "        s_material_inputs.append(s_material)\n",
    "        s_step_inputs.append(s_step)\n",
    "        a_elem_inputs.append(a_elem)\n",
    "        a_comp_inputs.append(a_comp)\n",
    "        Q_targets.append(Q_target)\n",
    "\n",
    "s_material_inputs = torch.stack(s_material_inputs)\n",
    "s_step_inputs = torch.stack(s_step_inputs)\n",
    "a_elem_inputs = torch.stack(a_elem_inputs)\n",
    "a_comp_inputs = torch.stack(a_comp_inputs)\n",
    "Q_targets = torch.stack(Q_targets)\n",
    "\n",
    "print('s_material_inputs:', s_material_inputs.shape)\n",
    "print('s_step_inputs:', s_step_inputs.shape)\n",
    "print('a_elem_inputs:', a_elem_inputs.shape)\n",
    "print('a_comp_inputs:', a_comp_inputs.shape)\n",
    "print('Q_targets:', Q_targets.shape)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch =  0 Loss = 864.4478\n",
      "Epoch =  1 Loss = 864.3575\n",
      "Epoch =  2 Loss = 864.2665\n",
      "Epoch =  3 Loss = 864.1745\n",
      "Epoch =  4 Loss = 864.0809\n",
      "Epoch =  5 Loss = 863.9853\n",
      "Epoch =  6 Loss = 863.8869\n",
      "Epoch =  7 Loss = 863.7855\n",
      "Epoch =  8 Loss = 863.6807\n",
      "Epoch =  9 Loss = 863.5716\n",
      "Epoch =  10 Loss = 863.4580\n",
      "Epoch =  11 Loss = 863.3397\n",
      "Epoch =  12 Loss = 863.2162\n",
      "Epoch =  13 Loss = 863.0870\n",
      "Epoch =  14 Loss = 862.9518\n",
      "Epoch =  15 Loss = 862.8105\n",
      "Epoch =  16 Loss = 862.6624\n",
      "Epoch =  17 Loss = 862.5072\n",
      "Epoch =  18 Loss = 862.3446\n",
      "Epoch =  19 Loss = 862.1741\n",
      "Epoch =  20 Loss = 861.9954\n",
      "Epoch =  21 Loss = 861.8081\n",
      "Epoch =  22 Loss = 861.6115\n",
      "Epoch =  23 Loss = 861.4056\n",
      "Epoch =  24 Loss = 861.1898\n",
      "Epoch =  25 Loss = 860.9636\n",
      "Epoch =  26 Loss = 860.7266\n",
      "Epoch =  27 Loss = 860.4785\n",
      "Epoch =  28 Loss = 860.2184\n",
      "Epoch =  29 Loss = 859.9463\n",
      "Epoch =  30 Loss = 859.6613\n",
      "Epoch =  31 Loss = 859.3631\n",
      "Epoch =  32 Loss = 859.0514\n",
      "Epoch =  33 Loss = 858.7251\n",
      "Epoch =  34 Loss = 858.3842\n",
      "Epoch =  35 Loss = 858.0276\n",
      "Epoch =  36 Loss = 857.6552\n",
      "Epoch =  37 Loss = 857.2663\n",
      "Epoch =  38 Loss = 856.8600\n",
      "Epoch =  39 Loss = 856.4362\n",
      "Epoch =  40 Loss = 855.9939\n",
      "Epoch =  41 Loss = 855.5324\n",
      "Epoch =  42 Loss = 855.0512\n",
      "Epoch =  43 Loss = 854.5496\n",
      "Epoch =  44 Loss = 854.0265\n",
      "Epoch =  45 Loss = 853.4815\n",
      "Epoch =  46 Loss = 852.9142\n",
      "Epoch =  47 Loss = 852.3238\n",
      "Epoch =  48 Loss = 851.7097\n",
      "Epoch =  49 Loss = 851.0706\n",
      "Epoch =  50 Loss = 850.4059\n",
      "Epoch =  51 Loss = 849.7151\n",
      "Epoch =  52 Loss = 848.9974\n",
      "Epoch =  53 Loss = 848.2517\n",
      "Epoch =  54 Loss = 847.4773\n",
      "Epoch =  55 Loss = 846.6733\n",
      "Epoch =  56 Loss = 845.8389\n",
      "Epoch =  57 Loss = 844.9735\n",
      "Epoch =  58 Loss = 844.0764\n",
      "Epoch =  59 Loss = 843.1467\n",
      "Epoch =  60 Loss = 842.1833\n",
      "Epoch =  61 Loss = 841.1849\n",
      "Epoch =  62 Loss = 840.1507\n",
      "Epoch =  63 Loss = 839.0794\n",
      "Epoch =  64 Loss = 837.9702\n",
      "Epoch =  65 Loss = 836.8221\n",
      "Epoch =  66 Loss = 835.6337\n",
      "Epoch =  67 Loss = 834.4037\n",
      "Epoch =  68 Loss = 833.1318\n",
      "Epoch =  69 Loss = 831.8165\n",
      "Epoch =  70 Loss = 830.4577\n",
      "Epoch =  71 Loss = 829.0539\n",
      "Epoch =  72 Loss = 827.6047\n",
      "Epoch =  73 Loss = 826.1089\n",
      "Epoch =  74 Loss = 824.5656\n",
      "Epoch =  75 Loss = 822.9733\n",
      "Epoch =  76 Loss = 821.3302\n",
      "Epoch =  77 Loss = 819.6352\n",
      "Epoch =  78 Loss = 817.8877\n",
      "Epoch =  79 Loss = 816.0866\n",
      "Epoch =  80 Loss = 814.2309\n",
      "Epoch =  81 Loss = 812.3192\n",
      "Epoch =  82 Loss = 810.3503\n",
      "Epoch =  83 Loss = 808.3236\n",
      "Epoch =  84 Loss = 806.2374\n",
      "Epoch =  85 Loss = 804.0897\n",
      "Epoch =  86 Loss = 801.8795\n",
      "Epoch =  87 Loss = 799.6068\n",
      "Epoch =  88 Loss = 797.2694\n",
      "Epoch =  89 Loss = 794.8673\n",
      "Epoch =  90 Loss = 792.3983\n",
      "Epoch =  91 Loss = 789.8621\n",
      "Epoch =  92 Loss = 787.2575\n",
      "Epoch =  93 Loss = 784.5835\n",
      "Epoch =  94 Loss = 781.8387\n",
      "Epoch =  95 Loss = 779.0219\n",
      "Epoch =  96 Loss = 776.1317\n",
      "Epoch =  97 Loss = 773.1662\n",
      "Epoch =  98 Loss = 770.1238\n",
      "Epoch =  99 Loss = 767.0022\n"
     ]
    }
   ],
   "source": [
    "# Train Q network\n",
    "optimizer = torch.optim.Adam(dqn.parameters(), lr=1e-2)\n",
    "loss_func = torch.nn.SmoothL1Loss().float()\n",
    "for epoch in range(100):\n",
    "    prediction = dqn(s_material = s_material_inputs, # torch.Size([batch_size, 40, 115]) and must be .float() !!!\n",
    "                    s_step      = s_step_inputs,     # torch.Size([batch_size,5])\n",
    "                    a_elem      = a_elem_inputs,     # torch.Size([batch_size,80])\n",
    "                    a_comp      = a_comp_inputs,  # torch.Size([batch_size,10])\n",
    "                    )                    # Input x and predict based on x\n",
    "    loss       = loss_func(prediction.float(), Q_targets.float()).float()   # Must be (1. nn output, 2. target)\n",
    "    optimizer.zero_grad()   # Clear gradients for next train\n",
    "    loss.backward()         # Backpropagation, compute gradients\n",
    "    optimizer.step()        # Apply gradients\n",
    "    print('Epoch = ', epoch, 'Loss = %.4f' % loss.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "30ac44dc31e4585f1a16d89332cf390870644b8479ac01e9bc1d71a88aa0f5e0"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('syn_gen_release': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
