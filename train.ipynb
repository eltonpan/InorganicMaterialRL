{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0., 1., 0., 0., 0.])]\n",
      "[5, 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from torch import nn\n",
    "import collections\n",
    "from model import DQN_pytorch\n",
    "import time\n",
    "from one_hot import onehot_target, element_set, comp_set, one_hot_to_element, element_to_one_hot, one_hot_to_comp, comp_to_one_hot, step_to_one_hot, one_hot_to_step\n",
    "import seaborn as sns\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "# Load Q_data_random\n",
    "with open('./data/Q_data_random.pkl', 'rb') as f:\n",
    "    Q_data_random = pickle.load(f)\n",
    "\n",
    "print(len(Q_data_random))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s_material_inputs: torch.Size([5000, 40, 115])\n",
      "s_step_inputs: torch.Size([5000, 5])\n",
      "a_elem_inputs: torch.Size([5000, 80])\n",
      "a_comp_inputs: torch.Size([5000, 10])\n",
      "Q_targets: torch.Size([5000, 1])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s_material_inputs = []\n",
    "s_step_inputs     = []\n",
    "a_elem_inputs     = []\n",
    "a_comp_inputs     = []\n",
    "Q_targets         = []\n",
    "\n",
    "for episode in Q_data_random:\n",
    "    for step in episode:\n",
    "        # state, action, reward = step\n",
    "        [s_material, s_step], [a_elem, a_comp], Q_target = step\n",
    "\n",
    "        s_material = torch.tensor(s_material)\n",
    "        s_step = torch.tensor(s_step)\n",
    "        a_elem = torch.tensor(a_elem)\n",
    "        a_comp = torch.tensor(a_comp)\n",
    "        Q_target = torch.tensor([Q_target])\n",
    "\n",
    "        s_material_inputs.append(s_material)\n",
    "        s_step_inputs.append(s_step)\n",
    "        a_elem_inputs.append(a_elem)\n",
    "        a_comp_inputs.append(a_comp)\n",
    "        Q_targets.append(Q_target)\n",
    "\n",
    "s_material_inputs = torch.stack(s_material_inputs)\n",
    "s_step_inputs = torch.stack(s_step_inputs)\n",
    "a_elem_inputs = torch.stack(a_elem_inputs)\n",
    "a_comp_inputs = torch.stack(a_comp_inputs)\n",
    "Q_targets = torch.stack(Q_targets)\n",
    "\n",
    "print('s_material_inputs:', s_material_inputs.shape)\n",
    "print('s_step_inputs:', s_step_inputs.shape)\n",
    "print('a_elem_inputs:', a_elem_inputs.shape)\n",
    "print('a_comp_inputs:', a_comp_inputs.shape)\n",
    "print('Q_targets:', Q_targets.shape)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/synthesisproject/anaconda3/envs/dqn/lib/python3.8/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot distribution of final rewards by random policy\n",
    "final_rewards_random = Q_targets[0::5].reshape(-1) # find final rewards\n",
    "sns.distplot(final_rewards_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s_material_inputs: torch.Size([5000, 40, 115])\n",
      "s_step_inputs: torch.Size([5000, 5])\n",
      "a_elem_inputs: torch.Size([5000, 80])\n",
      "a_comp_inputs: torch.Size([5000, 10])\n",
      "Q_targets: torch.Size([5000, 1])\n"
     ]
    }
   ],
   "source": [
    "sample_size = 5000\n",
    "s_material_inputs = s_material_inputs[:sample_size,:]\n",
    "s_step_inputs = s_step_inputs[:sample_size,:]\n",
    "a_elem_inputs = a_elem_inputs[:sample_size,:]\n",
    "a_comp_inputs = a_comp_inputs[:sample_size,:]\n",
    "Q_targets = Q_targets[:sample_size,:]\n",
    "print('s_material_inputs:', s_material_inputs.shape)\n",
    "print('s_step_inputs:', s_step_inputs.shape)\n",
    "print('a_elem_inputs:', a_elem_inputs.shape)\n",
    "print('a_comp_inputs:', a_comp_inputs.shape)\n",
    "print('Q_targets:', Q_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch =  0 Loss = 868.1480\n",
      "Epoch =  1 Loss = 867.6961\n",
      "Epoch =  2 Loss = 867.1245\n",
      "Epoch =  3 Loss = 866.2666\n",
      "Epoch =  4 Loss = 865.0073\n",
      "Epoch =  5 Loss = 863.2105\n",
      "Epoch =  6 Loss = 860.6968\n",
      "Epoch =  7 Loss = 857.2482\n",
      "Epoch =  8 Loss = 852.5936\n",
      "Epoch =  9 Loss = 846.3938\n",
      "Epoch =  10 Loss = 838.2410\n",
      "Epoch =  11 Loss = 827.6350\n",
      "Epoch =  12 Loss = 813.9680\n",
      "Epoch =  13 Loss = 796.5039\n",
      "Epoch =  14 Loss = 774.3755\n",
      "Epoch =  15 Loss = 746.5623\n",
      "Epoch =  16 Loss = 711.8346\n",
      "Epoch =  17 Loss = 668.7792\n",
      "Epoch =  18 Loss = 615.7836\n",
      "Epoch =  19 Loss = 551.0671\n",
      "Epoch =  20 Loss = 472.9024\n",
      "Epoch =  21 Loss = 380.9644\n",
      "Epoch =  22 Loss = 282.1129\n",
      "Epoch =  23 Loss = 202.3414\n",
      "Epoch =  24 Loss = 190.5188\n",
      "Epoch =  25 Loss = 257.1135\n",
      "Epoch =  26 Loss = 316.9601\n",
      "Epoch =  27 Loss = 325.4972\n",
      "Epoch =  28 Loss = 294.0145\n",
      "Epoch =  29 Loss = 245.8344\n",
      "Epoch =  30 Loss = 203.8334\n",
      "Epoch =  31 Loss = 183.4404\n",
      "Epoch =  32 Loss = 186.1847\n",
      "Epoch =  33 Loss = 202.2679\n",
      "Epoch =  34 Loss = 219.7696\n",
      "Epoch =  35 Loss = 231.2810\n",
      "Epoch =  36 Loss = 234.0840\n",
      "Epoch =  37 Loss = 228.4029\n",
      "Epoch =  38 Loss = 216.2338\n",
      "Epoch =  39 Loss = 200.9602\n",
      "Epoch =  40 Loss = 186.9581\n",
      "Epoch =  41 Loss = 178.6045\n",
      "Epoch =  42 Loss = 178.0023\n",
      "Epoch =  43 Loss = 183.9928\n",
      "Epoch =  44 Loss = 191.8202\n",
      "Epoch =  45 Loss = 196.2808\n",
      "Epoch =  46 Loss = 194.6610\n",
      "Epoch =  47 Loss = 188.0407\n",
      "Epoch =  48 Loss = 180.0105\n",
      "Epoch =  49 Loss = 174.0951\n",
      "Epoch =  50 Loss = 172.0379\n",
      "Epoch =  51 Loss = 173.3817\n",
      "Epoch =  52 Loss = 176.0462\n",
      "Epoch =  53 Loss = 178.0401\n",
      "Epoch =  54 Loss = 178.0969\n",
      "Epoch =  55 Loss = 176.0405\n",
      "Epoch =  56 Loss = 172.6294\n",
      "Epoch =  57 Loss = 169.0655\n",
      "Epoch =  58 Loss = 166.5800\n",
      "Epoch =  59 Loss = 165.7078\n",
      "Epoch =  60 Loss = 166.1251\n",
      "Epoch =  61 Loss = 166.8870\n",
      "Epoch =  62 Loss = 167.0183\n",
      "Epoch =  63 Loss = 165.9733\n",
      "Epoch =  64 Loss = 164.0130\n",
      "Epoch =  65 Loss = 161.9282\n",
      "Epoch =  66 Loss = 160.3911\n",
      "Epoch =  67 Loss = 159.5633\n",
      "Epoch =  68 Loss = 159.3049\n",
      "Epoch =  69 Loss = 159.2166\n",
      "Epoch =  70 Loss = 158.8058\n",
      "Epoch =  71 Loss = 157.8909\n",
      "Epoch =  72 Loss = 156.6063\n",
      "Epoch =  73 Loss = 155.3052\n",
      "Epoch =  74 Loss = 154.2335\n",
      "Epoch =  75 Loss = 153.5303\n",
      "Epoch =  76 Loss = 153.1483\n",
      "Epoch =  77 Loss = 152.8055\n",
      "Epoch =  78 Loss = 152.2202\n",
      "Epoch =  79 Loss = 151.3549\n",
      "Epoch =  80 Loss = 150.3792\n",
      "Epoch =  81 Loss = 149.5767\n",
      "Epoch =  82 Loss = 149.0724\n",
      "Epoch =  83 Loss = 148.7372\n",
      "Epoch =  84 Loss = 148.4066\n",
      "Epoch =  85 Loss = 147.9681\n",
      "Epoch =  86 Loss = 147.4323\n",
      "Epoch =  87 Loss = 146.8730\n",
      "Epoch =  88 Loss = 146.3875\n",
      "Epoch =  89 Loss = 146.0304\n",
      "Epoch =  90 Loss = 145.7879\n",
      "Epoch =  91 Loss = 145.5582\n",
      "Epoch =  92 Loss = 145.2949\n",
      "Epoch =  93 Loss = 144.9878\n",
      "Epoch =  94 Loss = 144.6833\n",
      "Epoch =  95 Loss = 144.4279\n",
      "Epoch =  96 Loss = 144.2568\n",
      "Epoch =  97 Loss = 144.1326\n",
      "Epoch =  98 Loss = 144.0223\n",
      "Epoch =  99 Loss = 143.8918\n",
      "time taken for batch: 71.64786958694458\n"
     ]
    }
   ],
   "source": [
    "# Initialize Q network\n",
    "dqn = DQN_pytorch()\n",
    "\n",
    "# Train Q network\n",
    "optimizer = torch.optim.Adam(dqn.parameters(), lr=1e-2)\n",
    "loss_func = torch.nn.SmoothL1Loss().float()\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(100):\n",
    "    prediction = dqn(s_material = s_material_inputs, # torch.Size([batch_size, 40, 115]) and must be .float() !!!\n",
    "                    s_step      = s_step_inputs,     # torch.Size([batch_size,5])\n",
    "                    a_elem      = a_elem_inputs,     # torch.Size([batch_size,80])\n",
    "                    a_comp      = a_comp_inputs,  # torch.Size([batch_size,10])\n",
    "                    )                    # Input x and predict based on x\n",
    "    loss       = loss_func(prediction.float(), Q_targets.float()).float()   # Must be (1. nn output, 2. target)\n",
    "    optimizer.zero_grad()   # Clear gradients for next train\n",
    "    loss.backward()         # Backpropagation, compute gradients\n",
    "    optimizer.step()        # Apply gradients\n",
    "    print('Epoch = ', epoch, 'Loss = %.4f' % loss.data.numpy())\n",
    "end = time.time()\n",
    "print('time taken for batch:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on BaTiO3:\n",
      "Max Q:  -617.170654296875\n",
      "Min Q:  -834.5386352539062\n",
      "max_a_elem:  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n",
      "max_a_comp:  (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n",
      "\n",
      "Based on LaAlO3:\n",
      "Max Q:  -617.211181640625\n",
      "Min Q:  -834.5791625976562\n",
      "max_a_elem:  (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n",
      "max_a_comp:  (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "def ranked_max_actions(state, dqn, n_actions = len(element_set)*len(comp_set)):\n",
    "    \"\"\"\n",
    "    Returns a list of ranked actions based on Q-network prodictions\n",
    "\n",
    "    Args:\n",
    "    state: List [s_material, s_step] where s_material is the string representation of material and s_step is the integer step number\n",
    "    dqn: Q-network for Q-value prediction\n",
    "\n",
    "    Returns:\n",
    "    ranked_max_actions: List [[s_material, s_step, Q-value]\n",
    "                              ...\n",
    "                              [s_material, s_step, Q-value]\n",
    "                              ]\n",
    "    where s_material is the one-hot torch.tensor.float() of material and\n",
    "    s_step is the  one-hot torch.tensor.float()\n",
    "    1st index corresponds to highest Q-value\n",
    "    \"\"\"\n",
    "\n",
    "    s_material, s_step = state\n",
    "    s_material = torch.tensor(onehot_target(s_material)).float() # Get one-hot rep of s_material\n",
    "    s_step = torch.tensor(step_to_one_hot([s_step])[0]).float() # Get one-hot rep of s_step\n",
    "\n",
    "    s_material_input = torch.stack([s_material]*n_actions)\n",
    "    s_step_input = torch.stack([s_step]*n_actions)\n",
    "\n",
    "    a_elem_input = []\n",
    "    a_comp_input = []\n",
    "    for elem in element_set:\n",
    "        a_elem = torch.tensor(element_to_one_hot([elem])[0]).float()\n",
    "        for comp in comp_set:\n",
    "            a_comp = torch.tensor(comp_to_one_hot([comp])[0]).float()\n",
    "\n",
    "            a_elem_input.append(a_elem)\n",
    "            a_comp_input.append(a_comp)\n",
    "    \n",
    "    a_elem_input = torch.stack(a_elem_input).float()\n",
    "    a_comp_input = torch.stack(a_comp_input).float()\n",
    "    \n",
    "    Q_pred = dqn(s_material = s_material_input, # torch.Size([batch_size, 40, 115]) and must be .float() !!!\n",
    "                    s_step      = s_step_input,     # torch.Size([batch_size,5])\n",
    "                    a_elem      = a_elem_input,     # torch.Size([batch_size,80])\n",
    "                    a_comp      = a_comp_input,  # torch.Size([batch_size,10])\n",
    "\n",
    "                )   \n",
    "    # Rank according to Q-values\n",
    "    Q_pred = Q_pred.detach().numpy()\n",
    "    Q_pred = Q_pred.reshape(len(element_set)*len(comp_set))\n",
    "    order = Q_pred.argsort()\n",
    "    ranks = order.argsort() # ranks of Q-values, 0th index = lowest Q, last index = highest Q\n",
    "    \n",
    "    \n",
    "    a_elem_input_ranked = torch.zeros([len(element_set)*len(comp_set), len(element_set)])\n",
    "    a_comp_input_ranked = torch.zeros([len(element_set)*len(comp_set), len(comp_set)])\n",
    "    Q_pred_ranked = np.zeros(len(element_set)*len(comp_set))\n",
    "\n",
    "    for rank in reversed(range(len(element_set)*len(comp_set))): # Start with most valuable\n",
    "        rank_idx = ranks[rank] # rank_idx = final position\n",
    "        rank_idx = (len(element_set)*len(comp_set) - 1) - rank_idx # Reverse rank_idx i.e. Want 0th index to correspond to max Q\n",
    "\n",
    "        # Sort Q-values\n",
    "        Q = Q_pred[rank]\n",
    "        Q_pred_ranked[rank_idx] = Q\n",
    "\n",
    "        # Sort a_elem according to Q-values\n",
    "        a_elem = a_elem_input[rank]\n",
    "        a_elem_input_ranked[rank_idx] = a_elem\n",
    "\n",
    "        # Sort a_elem according to Q-values\n",
    "        a_comp = a_comp_input[rank]\n",
    "        a_comp_input_ranked[rank_idx] = a_comp\n",
    "\n",
    "    # print(Q_pred_ranked.shape)\n",
    "    # print(a_elem_input_ranked.shape)\n",
    "    # print(a_comp_input_ranked.shape)\n",
    "    print('Max Q: ', max(Q_pred_ranked))\n",
    "    print('Min Q: ', min(Q_pred_ranked))\n",
    "\n",
    "    return a_elem_input_ranked, a_comp_input_ranked, Q_pred_ranked\n",
    "\n",
    "mat_1 = 'BaTiO3'\n",
    "mat_2 = 'LaAlO3'\n",
    "\n",
    "print('Based on {}:'.format(mat_1))\n",
    "a_elem_input_ranked, a_comp_input_ranked, Q_pred_ranked = ranked_max_actions([mat_1, 1], dqn = dqn)\n",
    "print('max_a_elem: ', tuple(a_elem_input_ranked[0].tolist()))\n",
    "print('max_a_comp: ', tuple(a_comp_input_ranked[0].tolist()))\n",
    "print('')\n",
    "\n",
    "print('Based on {}:'.format(mat_2))\n",
    "a_elem_input_ranked, a_comp_input_ranked, Q_pred_ranked = ranked_max_actions([mat_2, 1], dqn = dqn)\n",
    "print('max_a_elem: ', tuple(a_elem_input_ranked[0].tolist()))\n",
    "print('max_a_comp: ', tuple(a_comp_input_ranked[0].tolist()))\n",
    "\n",
    "# s_material = torch.tensor(onehot_target(\n",
    "#                                         'LaAlO3'\n",
    "#                                         )).reshape([1,40,115]).float() # Get one-hot rep of s_material\n",
    "\n",
    "\n",
    "# s_step = torch.tensor(step_to_one_hot([1])[0]).reshape([1,5]).float() # Get one-hot rep of s_step\n",
    "# print('')\n",
    "\n",
    "# print('Max Q:', dqn(s_material = s_material, # torch.Size([batch_size, 40, 115]) and must be .float() !!!\n",
    "#           s_step     = s_step,     # torch.Size([batch_size,5])\n",
    "#           a_elem     = a_elem_input_ranked[0].reshape(1,80),     # torch.Size([batch_size,80])\n",
    "#           a_comp     = a_comp_input_ranked[0].reshape(1,10),  # torch.Size([batch_size,10])\n",
    "# ).item())\n",
    "# print('Min Q:', dqn(s_material = s_material, # torch.Size([batch_size, 40, 115]) and must be .float() !!!\n",
    "#           s_step     = s_step,     # torch.Size([batch_size,5])\n",
    "#           a_elem     = a_elem_input_ranked[-1].reshape(1,80),     # torch.Size([batch_size,80])\n",
    "#           a_comp     = a_comp_input_ranked[-1].reshape(1,10),  # torch.Size([batch_size,10])\n",
    "# ).item())\n",
    "# print('Max a_elem: ', a_elem_input_ranked[idx])\n",
    "# print('Max a_comp: ', a_comp_input_ranked[idx])\n",
    "\n",
    "\n",
    "# Q_pred = Q_pred.detach().numpy()\n",
    "# Q_pred = Q_pred.reshape(len(element_set)*len(comp_set))\n",
    "# order = Q_pred.argsort()\n",
    "# ranks = order.argsort() # ranks of Q-values, 0th index = lowest Q, last index = highest Q\n",
    "# ranks[71], a[71], max(a)\n",
    "\n",
    "# Q_pred_ranked = np.zeros(len(element_set)*len(comp_set))\n",
    "# for rank in reversed(range(len(element_set)*len(comp_set))): # Start with most valuable\n",
    "#     rank_idx = ranks[rank] # rank_idx = index of ranks\n",
    "\n",
    "    \n",
    "#     Q = Q_pred[rank]\n",
    "#     Q_pred_ranked[rank_idx] = Q\n",
    "# Q_pred_ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0189, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1896, grad_fn=<MeanBackward0>),\n",
       " tensor(0.2236, grad_fn=<MeanBackward0>),\n",
       " tensor(0.1695, grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investigate weights of dqn\n",
    "dqn.fc1.weight.mean(), dqn.fc2.weight.mean(), dqn.fc3.weight.mean(), dqn.fc4.weight.mean(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1033.1884]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "s_material = torch.tensor(onehot_target('BaTiO3'))\n",
    "s_material = s_material.reshape(1, s_material.shape[0], s_material.shape[1])\n",
    "# print(s_material.shape)\n",
    "\n",
    "s_step = torch.zeros(5)\n",
    "s_step[3] = 1.\n",
    "s_step = s_step.reshape(1, s_step.shape[0])\n",
    "# print(s_step.shape)\n",
    "\n",
    "a_elem = torch.zeros(80)\n",
    "a_elem[2] = 1.\n",
    "a_elem = a_elem.reshape(1, a_elem.shape[0])\n",
    "# print(a_elem.shape)\n",
    "\n",
    "a_comp = torch.zeros(10)\n",
    "a_comp[1] = 1.\n",
    "a_comp = a_comp.reshape(1, a_comp.shape[0])\n",
    "# print(a_comp.shape)\n",
    "\n",
    "output = dqn(s_material, s_step, a_elem, a_comp)\n",
    "print(output)\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/synthesisproject/anaconda3/envs/dqn/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -848.414\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[([array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]),\n",
       "   array([1., 0., 0., 0., 0.])],\n",
       "  [(0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0),\n",
       "   (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0)],\n",
       "  0),\n",
       " ([array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]),\n",
       "   array([0., 1., 0., 0., 0.])],\n",
       "  [(0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0),\n",
       "   (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0)],\n",
       "  0),\n",
       " ([array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 1., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]),\n",
       "   array([0., 0., 1., 0., 0.])],\n",
       "  [(0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0),\n",
       "   (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0)],\n",
       "  0),\n",
       " ([array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]),\n",
       "   array([0., 0., 0., 1., 0.])],\n",
       "  [(0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0),\n",
       "   (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0)],\n",
       "  0),\n",
       " ([array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]),\n",
       "   array([0., 0., 0., 0., 1.])],\n",
       "  [(0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    1.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0,\n",
       "    0.0),\n",
       "   (0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0)],\n",
       "  -852.19196)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from env import MaterialEnvironment, extract_data_from_ep\n",
    "env = MaterialEnvironment(element_set = element_set,\n",
    "                          comp_set =  comp_set,)\n",
    "\n",
    "def generate_max_act(state, dqn):\n",
    "    '''\n",
    "    Generates max action.\n",
    "    Args:\n",
    "    a_elem_input_ranked: torch.tensor with index 0 = max a_elem and index -1 = min a_elem\n",
    "    a_comp_input_ranked: torch.tensor with index 0 = max a_comp and index -1 = min a_comp\n",
    "\n",
    "    Returns: max_a_elem, max_a_comp\n",
    "    '''\n",
    "    a_elem_input_ranked, a_comp_input_ranked, _ = ranked_max_actions(state = state, dqn = dqn, n_actions = len(element_set)*len(comp_set))\n",
    "    max_a_elem = a_elem_input_ranked[0] # 0th index corresponds to max\n",
    "    max_a_comp = a_comp_input_ranked[0] # 0th index corresponds to max\n",
    "\n",
    "    return max_a_elem, max_a_comp\n",
    "\n",
    "def generate_ep_with_dqn(dqn, epsilon = 0, max_steps = 5):\n",
    "    '''\n",
    "    Generates an episode with trained DQN\n",
    "    \n",
    "    Args:\n",
    "    dqn: Q-network for Q-value prediction\n",
    "    max_steps: Int\n",
    "\n",
    "    Returns: \n",
    "    env.path (an episode): List of SAR data in the form of [[material, step], [element, composition], reward]\n",
    "    \n",
    "    '''\n",
    "    env.initialize()\n",
    "    # print(env.state)\n",
    "    # print(env.counter)\n",
    "    for i in range(max_steps):\n",
    "        # if env.counter == 0: # if start of episode, choose random first element #########################\n",
    "        #     env.state = random.sample(element_set, 1)[0]\n",
    "        # Max action\n",
    "        max_a_elem, max_a_comp = generate_max_act(state = [env.state, env.counter+1], dqn = dqn)\n",
    "        max_a_elem = tuple(max_a_elem.tolist())\n",
    "        max_a_comp = tuple(max_a_comp.tolist())\n",
    "        action = [max_a_elem, max_a_comp]\n",
    "\n",
    "        # Take step with action\n",
    "        env.step(action)\n",
    "        print('step:', env.counter)\n",
    "        print('state:',env.state)\n",
    "        print('reward:',env.reward())\n",
    "        # print(env.num_steps_taken)\n",
    "        print('')\n",
    "    return env.path\n",
    "generate_ep_with_dqn(dqn = dqn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -849.5951\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -840.546\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -844.6521\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -848.635\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -841.84406\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -835.579\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -850.24896\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -843.776\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -839.491\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -853.678\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -841.29095\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -845.90594\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -850.73706\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -850.633\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -845.457\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -841.45703\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -847.14294\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -841.926\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -847.74603\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -847.77704\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -844.32495\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -848.4509\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -849.394\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -844.313\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -847.17505\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -846.503\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -848.9031\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -836.85406\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -844.327\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -841.63904\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -846.2389\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -848.596\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -845.567\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -842.493\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -845.38495\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -841.245\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -841.8501\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -846.257\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -850.6481\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -849.43195\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -853.95703\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -844.707\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -847.0139\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -839.54694\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -844.716\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -844.68604\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -847.913\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -843.418\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -840.83295\n",
      "\n",
      "Max Q:  -611.6607666015625\n",
      "Min Q:  -829.0287475585938\n",
      "step: 1\n",
      "state: V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -660.4310302734375\n",
      "Min Q:  -877.7990112304688\n",
      "step: 2\n",
      "state: V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -753.6856079101562\n",
      "Min Q:  -971.0536499023438\n",
      "step: 3\n",
      "state: V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -853.3724975585938\n",
      "Min Q:  -1070.740478515625\n",
      "step: 4\n",
      "state: V4V4V4V4\n",
      "reward: 0\n",
      "\n",
      "Max Q:  -931.8585205078125\n",
      "Min Q:  -1149.2265625\n",
      "step: 5\n",
      "state: V4V4V4V4V4\n",
      "reward: -838.9699\n",
      "\n",
      "time taken: 20.97738003730774\n"
     ]
    }
   ],
   "source": [
    "# ========= FOR TRAINED POLICY ===========\n",
    "start = time.time()\n",
    "#Generate episodes with DQN\n",
    "num_eps = 50\n",
    "episodes = []\n",
    "for j in range(num_eps):\n",
    "    episode = generate_ep_with_dqn(dqn = dqn)\n",
    "    episodes.append(episode)\n",
    "\n",
    "Q_data_trained = []\n",
    "# Extract Q_data from episodes\n",
    "for episode in episodes:\n",
    "    Q_data = extract_data_from_ep(episode)\n",
    "    Q_data_trained.append(Q_data)\n",
    "end = time.time()\n",
    "print('time taken:', end - start)\n",
    "\n",
    "# Save Q_data\n",
    "with open('./data/Q_data_trained.pkl', 'wb') as f:\n",
    "    pickle.dump(Q_data_trained, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "Q_targets: torch.Size([250, 1])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Q_data_random\n",
    "with open('./data/Q_data_trained.pkl', 'rb') as f:\n",
    "    Q_data_trained = pickle.load(f)\n",
    "\n",
    "print(len(Q_data_trained))\n",
    "\n",
    "Q_targets_trained         = []\n",
    "\n",
    "for episode in Q_data_trained:\n",
    "    for step in episode:\n",
    "        # state, action, reward = step\n",
    "        _, _, Q_target = step\n",
    "        Q_target = torch.tensor([Q_target])\n",
    "        Q_targets_trained.append(Q_target)\n",
    "\n",
    "Q_targets_trained = torch.stack(Q_targets_trained)\n",
    "print('Q_targets:', Q_targets_trained.shape)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/synthesisproject/anaconda3/envs/dqn/lib/python3.8/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/synthesisproject/anaconda3/envs/dqn/lib/python3.8/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot distribution of final rewards by random vs trained policy\n",
    "final_rewards_trained = Q_targets_trained[0::5].reshape(-1) # find final rewards\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.distplot(final_rewards_random, hist = True, norm_hist = True, label = 'Random')\n",
    "sns.distplot(final_rewards_trained, hist = True, norm_hist = True, label = 'Trained_5k_100ep')\n",
    "plt.ylabel('Probability density')\n",
    "plt.xlabel('Reward')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "30ac44dc31e4585f1a16d89332cf390870644b8479ac01e9bc1d71a88aa0f5e0"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('syn_gen_release': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
